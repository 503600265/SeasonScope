{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7lbrTdjG6LUx","executionInfo":{"status":"ok","timestamp":1701456795114,"user_tz":300,"elapsed":17310,"user":{"displayName":"Jennifer Duan","userId":"02371767141346923175"}},"outputId":"a6c23dfc-06aa-46b5-b2bd-a3f282fc5db7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!cp \"/content/drive/MyDrive/ColumbiaMSCS/COMS4995_DL_for_CV/Project/Data/project_data.zip\" \"/content/project_data.zip\""],"metadata":{"id":"vTZ48PYK4CN-","executionInfo":{"status":"ok","timestamp":1701456883891,"user_tz":300,"elapsed":78976,"user":{"displayName":"Jennifer Duan","userId":"02371767141346923175"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!mkdir -p \"/content/data\""],"metadata":{"id":"PL4QA5Uo4O-w","executionInfo":{"status":"ok","timestamp":1701456949132,"user_tz":300,"elapsed":306,"user":{"displayName":"Jennifer Duan","userId":"02371767141346923175"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!unzip -q \"/content/project_data.zip\" -d \"/content/data\""],"metadata":{"id":"8lThtVk74SGa","executionInfo":{"status":"ok","timestamp":1701457013108,"user_tz":300,"elapsed":62565,"user":{"displayName":"Jennifer Duan","userId":"02371767141346923175"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, Subset, random_split\n","from torchvision import models\n","from torchvision.models import googlenet, GoogLeNet_Weights\n","import numpy as np\n","import os\n","import shutil\n","import glob\n","import matplotlib.pyplot as plt\n","import random"],"metadata":{"id":"QCT0LhmvVcLR","executionInfo":{"status":"ok","timestamp":1701457021668,"user_tz":300,"elapsed":6166,"user":{"displayName":"Jennifer Duan","userId":"02371767141346923175"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Count of each class in the data\n","project_data = {}\n","\n","project_data['spring'] = glob.glob('/content/data/project_data/spring/spring*')\n","project_data['summer'] = glob.glob('/content/data/project_data/summer/summer*')\n","project_data['fall'] = glob.glob('/content/data/project_data/fall/fall*')\n","project_data['winter'] = glob.glob('/content/data/project_data/winter/winter*')\n","\n","print(f\"count of spring images :  {len(project_data['spring'])}\")\n","print(f\"count of summer images :  {len(project_data['summer'])}\")\n","print(f\"count of fall images :  {len(project_data['fall'])}\")\n","print(f\"count of winter images :  {len(project_data['winter'])}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k0Rea0SHbUl9","executionInfo":{"status":"ok","timestamp":1701457027269,"user_tz":300,"elapsed":151,"user":{"displayName":"Jennifer Duan","userId":"02371767141346923175"}},"outputId":"367657d1-9cdd-456a-c372-07e958091ae6"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["count of spring images :  6000\n","count of summer images :  6000\n","count of fall images :  6000\n","count of winter images :  6000\n"]}]},{"cell_type":"code","source":["SOURCE = '/content/data/project_data'\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"-qC3fENvcDkd","executionInfo":{"status":"ok","timestamp":1701457030509,"user_tz":300,"elapsed":136,"user":{"displayName":"Jennifer Duan","userId":"02371767141346923175"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","dataset = datasets.ImageFolder(root=SOURCE, transform=transform)"],"metadata":{"id":"-CHlDm5lcWGv","executionInfo":{"status":"ok","timestamp":1701457032575,"user_tz":300,"elapsed":153,"user":{"displayName":"Jennifer Duan","userId":"02371767141346923175"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Use 4,800 images of each category for traning, 600 of each category for validation, 600 images of each category for testing\n","fall_samples = []\n","spring_samples = []\n","summer_samples = []\n","winter_samples = []\n","\n","# Separate dataset into four label groups\n","for i in range(len(dataset)):\n","    _, label = dataset[i]\n","    if label == 0:\n","        fall_samples.append(i)\n","    elif label == 1:\n","        spring_samples.append(i)\n","    elif label == 2:\n","        summer_samples.append(i)\n","    else:\n","        winter_samples.append(i)\n","\n","# Shuffle the samples\n","random.shuffle(fall_samples)\n","random.shuffle(spring_samples)\n","random.shuffle(summer_samples)\n","random.shuffle(winter_samples)\n","\n","# Split the samples\n","train_indices = fall_samples[:4800] + spring_samples[:4800] + summer_samples[:4800] + winter_samples[:4800]\n","val_indices = fall_samples[4800:5400] + spring_samples[4800:5400] + summer_samples[4800:5400] + winter_samples[4800:5400]\n","test_indices = fall_samples[5400:6000] + spring_samples[5400:6000] + summer_samples[5400:6000] + winter_samples[5400:6000]\n","\n","# Shuffle the indices\n","random.shuffle(train_indices)\n","random.shuffle(val_indices)\n","random.shuffle(test_indices)\n","\n","# Create subset datasets\n","train_dataset = Subset(dataset, train_indices)\n","val_dataset = Subset(dataset, val_indices)\n","test_dataset = Subset(dataset, test_indices)"],"metadata":{"id":"nemoJyjggLiq","executionInfo":{"status":"ok","timestamp":1701457685109,"user_tz":300,"elapsed":649713,"user":{"displayName":"Jennifer Duan","userId":"02371767141346923175"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Create data loaders\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"],"metadata":{"id":"FY4njLdDimG0","executionInfo":{"status":"ok","timestamp":1701459769193,"user_tz":300,"elapsed":177,"user":{"displayName":"Jennifer Duan","userId":"02371767141346923175"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Load pre-trained GoogLeNet\n","model_googlenet = googlenet(weights=GoogLeNet_Weights.DEFAULT)"],"metadata":{"id":"wWCRScjHisf0","executionInfo":{"status":"ok","timestamp":1701461959521,"user_tz":300,"elapsed":618,"user":{"displayName":"Jennifer Duan","userId":"02371767141346923175"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Change the final fully connected layer's output feature size to 4 so that\n","# it's suitable for softmax activation for classification on four seasons\n","model_googlenet.fc.out_features = 4"],"metadata":{"id":"oTEOPAeZjuB8","executionInfo":{"status":"ok","timestamp":1701461963333,"user_tz":300,"elapsed":136,"user":{"displayName":"Jennifer Duan","userId":"02371767141346923175"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Use GPU\n","model_googlenet = model_googlenet.to(DEVICE)\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model_googlenet.parameters(), lr=0.001, momentum=0.9)\n","softmax = nn.Softmax(dim=1)"],"metadata":{"id":"zRDN0XOekN21","executionInfo":{"status":"ok","timestamp":1701461966703,"user_tz":300,"elapsed":133,"user":{"displayName":"Jennifer Duan","userId":"02371767141346923175"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# Define training function\n","def train_model(model, train_loader, val_loader, loss_fn, optimizer, epochs, threshold):\n","    best_val_loss = float('inf')\n","    degrade_times = 0\n","    for epoch in range(epochs):\n","        train_loss = 0.0\n","        train_corrects = 0\n","        train_count = 0\n","        model.train()\n","        for x_batch, y_batch in train_loader:\n","            x_batch, y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)\n","            optimizer.zero_grad()\n","            outputs = model(x_batch)\n","            loss = loss_fn(outputs, y_batch)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item() * len(y_batch)\n","            pred = softmax(outputs)\n","            train_corrects += (torch.argmax(pred, dim=1) == y_batch).float().sum()\n","            train_count += y_batch.size(0)\n","        train_loss = train_loss / len(train_loader.dataset)\n","        train_acc = train_corrects / train_count\n","\n","        val_loss = 0.0\n","        val_corrects = 0\n","        val_count = 0\n","        model.eval()\n","        with torch.no_grad():\n","            for x_batch, y_batch in val_loader:\n","                x_batch, y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)\n","                outputs = model(x_batch)\n","                loss = loss_fn(outputs, y_batch)\n","                val_loss += loss.item() * len(y_batch)\n","                pred = softmax(outputs)\n","                val_corrects += (torch.argmax(pred, dim=1) == y_batch).float().sum()\n","                val_count += y_batch.size(0)\n","        val_loss = val_loss / len(val_loader.dataset)\n","        val_acc = val_corrects / val_count\n","        print(f'Epoch {epoch} Train Loss {train_loss:.4f} Train Accuracy {train_acc:.4f} Validation Loss {val_loss:.4f} Validation Accuracy {val_acc:.4f}')\n","\n","        # Check for early stopping\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            degrade_times = 0\n","            # Save the model if it has the best validation loss so far\n","            torch.save(model.state_dict(), './best_model_googlenet.pth')\n","        else:\n","            degrade_times += 1\n","            # If the number of epochs where validation loss continuously increases\n","            # is larger than threshold, stop training the network to avoid overfitting\n","            if degrade_times > threshold:\n","                print(f'Early stopping at epoch {epoch}')\n","                break"],"metadata":{"id":"MI9cMwvWkl6G","executionInfo":{"status":"ok","timestamp":1701461981291,"user_tz":300,"elapsed":136,"user":{"displayName":"Jennifer Duan","userId":"02371767141346923175"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# Define evaluation function\n","def evaluate_model(model, test_loader):\n","    correct = 0\n","    count = 0\n","    model.eval()\n","    with torch.no_grad():\n","        for x_batch, y_batch in test_loader:\n","            x_batch, y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)\n","            outputs = model(x_batch)\n","            pred = softmax(outputs)\n","            correct += (torch.argmax(pred, dim=1) == y_batch).float().sum()\n","            count += y_batch.size(0)\n","        test_acc = correct / count\n","    print(f'Accuracy on test set: {test_acc:.4f}')"],"metadata":{"id":"TpMswxJ0lY7u","executionInfo":{"status":"ok","timestamp":1701461982437,"user_tz":300,"elapsed":139,"user":{"displayName":"Jennifer Duan","userId":"02371767141346923175"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Fine-tune the network on seasons image data\n","train_model(model_googlenet, train_loader, val_loader, loss_fn, optimizer, epochs=10, threshold=3)"],"metadata":{"id":"gWBQIH14llxY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701466554618,"user_tz":300,"elapsed":4570930,"user":{"displayName":"Jennifer Duan","userId":"02371767141346923175"}},"outputId":"a1c62a8a-9862-44ca-d02c-095135e54b44"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 Train Loss 1.0882 Train Accuracy 0.6502 Validation Loss 0.6843 Validation Accuracy 0.7375\n","Epoch 1 Train Loss 0.6337 Train Accuracy 0.7557 Validation Loss 0.6511 Validation Accuracy 0.7492\n","Epoch 2 Train Loss 0.5405 Train Accuracy 0.7945 Validation Loss 0.6478 Validation Accuracy 0.7529\n","Epoch 3 Train Loss 0.4517 Train Accuracy 0.8280 Validation Loss 0.6750 Validation Accuracy 0.7433\n","Epoch 4 Train Loss 0.3675 Train Accuracy 0.8622 Validation Loss 0.7182 Validation Accuracy 0.7454\n","Epoch 5 Train Loss 0.2928 Train Accuracy 0.8923 Validation Loss 0.7580 Validation Accuracy 0.7504\n","Epoch 6 Train Loss 0.2340 Train Accuracy 0.9177 Validation Loss 0.8259 Validation Accuracy 0.7492\n","Early stopping at epoch 6\n"]}]},{"cell_type":"code","source":["# Load the best model\n","model_googlenet.load_state_dict(torch.load('./best_model_googlenet.pth'))\n","# Evaluate on the test set\n","evaluate_model(model_googlenet, test_loader)"],"metadata":{"id":"lWFoX0OrlrVi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701466685709,"user_tz":300,"elapsed":70530,"user":{"displayName":"Jennifer Duan","userId":"02371767141346923175"}},"outputId":"a4fb4c5e-0c2f-4e01-e670-64d5b11e038f"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on test set: 0.7346\n"]}]}]}